package de.frosner.dds.util

import de.frosner.dds.core.ScalaFunctions
import de.frosner.dds.servables.{Table, KeyValueSequence}
import org.apache.spark.sql.Row
import org.apache.spark.sql.types._
import org.apache.spark.util.StatCounter

object ServableUtils {

  private def lg2IntCeil(number: Long): Int = {
    //integer lg_2 can be calculated by bitshifting
    var log = 0
    var countDown = number
    while (countDown > 1) {
      countDown = countDown >> 1
      log += 1
    }
    //ceiling by checking whether each LSB was zero, adding 1 if not.
    if (number == (1 << log) || number == 0)
      log
    else
      log + 1
  }

  /**
   * Compute the "optimal" number of bins for a histogram using the Sturge's formula. This assumes that the data
   * is generated by a Gaussian distribution.
   *
   * @param count Number of data points in the sample
   * @return Optimal number of bins
   */
  def optimalNumberOfBins(count: Long): Int = lg2IntCeil(count) + 1

  def statCounterToKeyValueSequence(stats: StatCounter, title: String): KeyValueSequence = {
    KeyValueSequence(
      title, List(
        ("Count", stats.count.toString),
        ("Sum", stats.sum.toString),
        ("Min", stats.min.toString),
        ("Max", stats.max.toString),
        ("Mean", stats.mean.toString),
        ("Stdev", stats.stdev.toString),
        ("Variance", stats.variance.toString)
      )
    )
  }

  def statCounterToTable(stat: StatCounter, title: String): Table =
    statCountersToTable(List.empty, List(stat), title)

  def statCountersToTable(labels: Seq[String], stats: Seq[StatCounter], title: String): Table = {
    val optionalLabelHead = if (labels.size > 0) List(StructField("label", StringType, false)) else List.empty
    val head = optionalLabelHead ++ List(
      StructField("count", LongType, false),
      StructField("sum", DoubleType, false),
      StructField("min", DoubleType, false),
      StructField("max", DoubleType, false),
      StructField("mean", DoubleType, false),
      StructField("stdev", DoubleType, false),
      StructField("variance", DoubleType, false)
    )
    val schema = StructType(head)
    val rows = if (labels.size > 0) {
      labels.zip(stats).map{ case (label, stats) =>
        Row(label, stats.count, stats.sum, stats.min, stats.max, stats.mean, stats.stdev, stats.variance)
      }
    } else {
      stats.map(stats => Row(stats.count, stats.sum, stats.min, stats.max, stats.mean, stats.stdev, stats.variance))
    }
    Table(title, schema, rows)
  }

}
